[1526461614.989][2018-05-16 05:06:54][osboxes][Transaction][transaction][event_create][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\t\n   })\t\t\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n\n\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526461614,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5158","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526461619.486][2018-05-16 05:06:59][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8vu3nt02","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5341","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526461693.396][2018-05-16 05:08:13][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8vvopc03","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5341","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526461851.343][2018-05-16 05:10:51][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8vz2kn04","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5341","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526461855.098][2018-05-16 05:10:55][osboxes][Transaction][transaction][job][Job completed successfully: jjh8vz2kn04][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\t\n   })\t\t\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n\n\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526461851,"source":"Manual (admin)","id":"jjh8vz2kn04","time_start":1526461851.335,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8vz2kn04.log","pid":7356,"jobid":"ForecastOptimizationjjh8vz2kn04","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526461855.098,"elapsed":3.763000011444092}]
[1526461977.598][2018-05-16 05:12:57][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526461977,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5229","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526461981.427][2018-05-16 05:13:01][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8w1uy405","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5331","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462128.42][2018-05-16 05:15:28][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.commit.reset' : latest\t\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\t\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\t\n   })\t\t\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n\n\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526462128,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5280","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462131.666][2018-05-16 05:15:31][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8w52vh06","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5382","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462203.606][2018-05-16 05:16:43][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.commit.reset' : 'latest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526462203,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5268","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462206.446][2018-05-16 05:16:46][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8w6okq07","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5370","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462365.534][2018-05-16 05:19:25][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'latest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526462365,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5268","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462368.297][2018-05-16 05:19:28][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wa5gk08","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5370","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462430.437][2018-05-16 05:20:30][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'earliest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526462430,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5270","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462434.08][2018-05-16 05:20:34][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wbk7u09","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462602.346][2018-05-16 05:23:22][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wf61x0a","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462695.573][2018-05-16 05:24:55][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wh5zj0b","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462702.407][2018-05-16 05:25:02][osboxes][Transaction][transaction][job][Job completed successfully: jjh8wh5zj0b][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'earliest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526462695,"source":"Manual (admin)","id":"jjh8wh5zj0b","time_start":1526462695.567,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8wh5zj0b.log","pid":8995,"jobid":"ForecastOptimizationjjh8wh5zj0b","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526462702.406,"elapsed":6.83899998664856}]
[1526462900.722][2018-05-16 05:28:20][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wlka50c","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526462906.69][2018-05-16 05:28:26][osboxes][Transaction][transaction][job][Job completed successfully: jjh8wlka50c][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'earliest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526462900,"source":"Manual (admin)","id":"jjh8wlka50c","time_start":1526462900.717,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8wlka50c.log","pid":9195,"jobid":"ForecastOptimizationjjh8wlka50c","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526462906.69,"elapsed":5.9730000495910645}]
[1526462920.047][2018-05-16 05:28:40][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wlz6z0d","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463257.547][2018-05-16 05:34:17][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wt7lx0e","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463352.961][2018-05-16 05:35:52][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wv98c0f","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463460.864][2018-05-16 05:37:40][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8wxkho0g","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463469.939][2018-05-16 05:37:49][osboxes][Transaction][transaction][job][Job completed successfully: jjh8wxkho0g][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'earliest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526463460,"source":"Manual (admin)","id":"jjh8wxkho0g","time_start":1526463460.86,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8wxkho0g.log","pid":10024,"jobid":"ForecastOptimizationjjh8wxkho0g","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526463469.939,"elapsed":9.078999996185303}]
[1526463612.492][2018-05-16 05:40:12][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8x0thi0h","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463685.113][2018-05-16 05:41:25][osboxes][Transaction][transaction][job][Job completed successfully: jjh8x0thi0h][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'earliest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526463612,"source":"Manual (admin)","id":"jjh8x0thi0h","time_start":1526463612.486,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8x0thi0h.log","pid":10224,"cpu":{"min":0.7,"max":3.3,"total":9.899999999999999,"count":7,"current":0.7},"mem":{"min":67739648,"max":67739648,"total":474177536,"count":7,"current":67739648},"jobid":"ForecastOptimizationjjh8x0thi0h","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526463685.113,"elapsed":72.6269998550415}]
[1526463861.042][2018-05-16 05:44:21][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526463861,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5270","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463868.076][2018-05-16 05:44:28][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8x6ap30i","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463903.971][2018-05-16 05:45:03][osboxes][Transaction][transaction][job][Job completed successfully: jjh8x6ap30i][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526463868,"source":"Manual (admin)","id":"jjh8x6ap30i","time_start":1526463868.071,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8x6ap30i.log","pid":10596,"cpu":{"min":1.2,"max":5.2,"total":10.299999999999999,"count":4,"current":1.2},"mem":{"min":68866048,"max":68866048,"total":275464192,"count":4,"current":68866048},"jobid":"ForecastOptimizationjjh8x6ap30i","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526463903.971,"elapsed":35.89999985694885}]
[1526463932.98][2018-05-16 05:45:32][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8x7orz0j","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526463938.188][2018-05-16 05:45:38][osboxes][Transaction][transaction][job][Job completed successfully: jjh8x7orz0j][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526463932,"source":"Manual (admin)","id":"jjh8x7orz0j","time_start":1526463932.975,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8x7orz0j.log","pid":10745,"jobid":"ForecastOptimizationjjh8x7orz0j","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526463938.188,"elapsed":5.213000059127808}]
[1526463953.377][2018-05-16 05:45:53][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8x84il0k","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5372","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526464130.448][2018-05-16 05:48:50][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'beginning'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526464130,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5271","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526464133.677][2018-05-16 05:48:53][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8xbzmv0l","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5373","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526464423.607][2018-05-16 05:53:43][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': false,\n      'auto.offset.reset' : 'earliest'\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526464423,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5271","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526464426.698][2018-05-16 05:53:46][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8xi9qd0m","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5373","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526464854.277][2018-05-16 06:00:54][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging debug messages, if debug is enabled\n    consumer.on('event.log', function(log) {\n      console.log(log);\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":1,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526464854,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5399","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526464864.41][2018-05-16 06:01:04][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8xrnh10n","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5501","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465262.468][2018-05-16 06:07:42][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging debug messages, if debug is enabled\n    consumer.on('event.log', function(log) {\n      console.log(log);\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(msg.value.toString());\n      if(record.jobid === jobid){\n        consumer.disconnect();\n        onNextMsgReceived(record);\n      }\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526465262,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5402","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465265.973][2018-05-16 06:07:45][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y09bl0o","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5504","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465283.007][2018-05-16 06:08:03][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y0mgr0p","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5504","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465307.57][2018-05-16 06:08:27][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y15eo0q","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5504","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465510.574][2018-05-16 06:11:50][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging debug messages, if debug is enabled\n    consumer.on('event.log', function(log) {\n      console.log(log);\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(\"Ciao arnaldo\")\n      console.log(msg.value.toString());\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526465510,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5325","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465513.976][2018-05-16 06:11:53][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y5kok0r","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5427","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465563.903][2018-05-16 06:12:43][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging debug messages, if debug is enabled\n    consumer.on('event.log', function(log) {\n      console.log(log);\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      //console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(\"Ciao arnaldo\")\n      console.log(msg.value.toString());\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526465563,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5327","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465567.865][2018-05-16 06:12:47][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y6q9h0s","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5429","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465582.57][2018-05-16 06:13:02][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y71lx0t","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5429","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465631.31][2018-05-16 06:13:51][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8y837u0u","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5429","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465955.698][2018-05-16 06:19:15][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n\n    // start consuming response\n    var consumer = new Kafka.KafkaConsumer({\n      //'debug': 'all',\n      'metadata.broker.list': process.env.BROKER_LIST,\n      'group.id': jobid,\n      'enable.auto.commit': true,\n      'auto.offset.reset' : 'smallest'\n    });\n    //logging debug messages, if debug is enabled\n    consumer.on('event.log', function(log) {\n      console.log(log);\n    });\n    //logging all errors\n    consumer.on('event.error',onConsumerError);\n    // when consumer is ready , subscribe to topics\n    consumer.on('ready', function(arg) {\n      console.log('consumer ready.' + JSON.stringify(arg));\n      consumer.subscribe([topicToConsume]);\n      //start consuming messages\n      consumer.consume();\n    });\n    consumer.on('data', function(msg) {\n      // Output the actual message contents\n      console.log(JSON.stringify(msg));\n      let record = JSON.parse(msg.value.toString());\n      console.log(\"Ciao arnaldo\")\n      console.log(msg.value.toString());\n    });\n    consumer.on('disconnected', function(arg) {\n      console.log('consumer disconnected. ' + JSON.stringify(arg));\n    });\n    //starting the consumer\n    consumer.connect();\n\n    process.on('SIGTERM',()=>{\n \t console.log('Sending a message to abort job');\n\t consumer.disconnect();\n \t trigger.operation = 'Abort';\n \t // send message to job trigger\n \t producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n   })\n\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526465955,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5325","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526465979.174][2018-05-16 06:19:39][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8yfjmq0v","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5427","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466004.205][2018-05-16 06:20:04][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8yg2y10w","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5427","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466250.366][2018-05-16 06:24:10][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = 'asdfasdf345' || `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true,\n  'auto.offset.reset' : 'smallest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526466250,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5348","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466293.584][2018-05-16 06:24:53][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = 'asdfasdf345' || `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true,\n  'auto.offset.reset' : 'smallest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526466293,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5348","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466297.254][2018-05-16 06:24:57][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8ymd1w0x","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5450","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466506.384][2018-05-16 06:28:26][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8yqufh0y","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5450","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466510.916][2018-05-16 06:28:30][osboxes][Transaction][transaction][job][Job completed successfully: jjh8yqufh0y][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = 'asdfasdf345' || `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n// Connect to the broker manually\nproducer.connect();\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true,\n  'auto.offset.reset' : 'smallest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n// Wait for the ready event before proceeding\nproducer.on('ready', function() {\n  try {\n    console.log('Producer is ready');\n    // send message to job trigger\n    producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n  } catch (err) {\n    console.error('A problem occurred when sending our message');\n    console.error(err);\n    process.exit(1)\n  }\n});\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526466506,"source":"Manual (admin)","id":"jjh8yqufh0y","time_start":1526466506.381,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8yqufh0y.log","pid":15344,"jobid":"asdfasdf345","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":479,"time_end":1526466510.916,"elapsed":4.534999847412109}]
[1526466669.878][2018-05-16 06:31:09][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = 'asdfasdf345' || `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true,\n  'auto.offset.reset' : 'smallest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526466669,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5378","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466672.383][2018-05-16 06:31:12][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8yuei90z","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5395","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466687.165][2018-05-16 06:31:27][osboxes][Transaction][transaction][job][Job completed successfully: jjh8yuei90z][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = 'asdfasdf345' || `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true,\n  'auto.offset.reset' : 'smallest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","now":1526466672,"source":"Manual (admin)","id":"jjh8yuei90z","time_start":1526466672.369,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","plugin_title":"Shell Script","category_title":"General","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh8yuei90z.log","pid":15663,"cpu":{"min":6.3,"max":6.3,"total":6.3,"count":1,"current":6.3},"mem":{"min":69206016,"max":69206016,"total":69206016,"count":1,"current":69206016},"jobid":"asdfasdf345","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":479,"time_end":1526466687.165,"elapsed":14.796000003814697}]
[1526466715.825][2018-05-16 06:31:55][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8yvc1810","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5480","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526466954.59][2018-05-16 06:35:54][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8z0g9h11","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5480","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526467648.509][2018-05-16 06:47:28][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = 'asdfasdf345' || `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526467648,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5386","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526467652.591][2018-05-16 06:47:32][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8zfeuj12","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5488","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526467704.723][2018-05-16 06:48:24][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8zgj2m13","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5488","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526467779.067][2018-05-16 06:49:39][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8zi4fr14","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5488","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526467900.326][2018-05-16 06:51:40][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8zkpzy15","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5488","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526467930.665][2018-05-16 06:52:10][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8zldet16","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5488","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526468031.517][2018-05-16 06:53:51][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8znj8717","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5488","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526468121.793][2018-05-16 06:55:21][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid = `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE || 'TriggerForecastOptimization' ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME || 'TriggerForecastOptimizationResponse';\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\nvalidate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT) || 1000,\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME || 1000  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526468121,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5369","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526468458.248][2018-05-16 07:00:58][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh8zwoh618","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5471","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526473768.026][2018-05-16 08:29:28][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid =  `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\n//validate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526473767,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5283","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526473771.178][2018-05-16 08:29:31][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh932jz619","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5385","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526473774.92][2018-05-16 08:29:34][osboxes][Transaction][transaction][job][Job completed successfully: jjh932jz619][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid =  `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\n//validate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526473771,"source":"Manual (admin)","id":"jjh932jz619","time_start":1526473771.17,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh932jz619.log","pid":24096,"jobid":"ForecastOptimizationjjh932jz619","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526473774.92,"elapsed":3.75}]
[1526473799.279][2018-05-16 08:29:59][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh9335nu1a","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5385","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526473803.079][2018-05-16 08:30:03][osboxes][Transaction][transaction][job][Job completed successfully: jjh9335nu1a][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid =  `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\n//validate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  //console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log(msg.value.toString());\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526473799,"source":"Manual (admin)","id":"jjh9335nu1a","time_start":1526473799.274,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh9335nu1a.log","pid":24166,"jobid":"ForecastOptimizationjjh9335nu1a","result":"Success","percentage":100,"progress":1,"complete":1,"code":0,"description":"","log_file_size":499,"time_end":1526473803.079,"elapsed":3.805000066757202}]
[1526473993.6][2018-05-16 08:33:13][osboxes][Transaction][transaction][event_update][ForecastOptimization][{"event":{"enabled":1,"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid =  `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\n//validate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log('A message received');\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timing":{"minutes":[0],"months":[5],"days":[16],"hours":[5]},"max_children":32,"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","title":"ForecastOptimization","category":"general","target":"allgrp","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","id":"ejh8vu06v01","modified":1526473993,"created":1526461614,"username":"admin"},"ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5281","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526474000.138][2018-05-16 08:33:20][osboxes][Transaction][transaction][job_run][ForecastOptimization][{"id":"jjh937gna1b","event":"ejh8vu06v01","ip":"::ffff:10.0.2.15","headers":{"host":"10.0.2.15:3012","connection":"keep-alive","content-length":"5383","accept":"text/plain, */*; q=0.01","origin":"http://localhost:3012","user-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/66.0.3359.139 Chrome/66.0.3359.139 Safari/537.36","content-type":"text/plain","referer":"http://localhost:3012/","accept-encoding":"gzip, deflate","accept-language":"it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7"},"username":"admin"}]
[1526474003.89][2018-05-16 08:33:23][osboxes][Transaction][transaction][job][Job completed successfully: jjh937gna1b][{"params":{"script":"#!/usr/bin/env node\n\n'use strict';\nlet Kafka = require('node-rdkafka');\nlet jobid =  `${process.env.JOB_EVENT_TITLE}${process.env.JOB_ID}`.replace(' ','');\nconst topicToProduce = process.env.TOPIC_TO_PRODUCE ;\nconst topicToConsume = process.env.TOPIC_TO_CONSUME ;\nlet requestDelay = process.env.REQUEST_DELAY || 10000;\n\n//validate();\n\nconsole.log('Creating producer')\nvar producer = new Kafka.Producer({\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'client.id': jobid ,\n  'dr_cb': true\n});\n//message body\nlet trigger = {\n  timeout : Number(process.env.JOB_TIMEOUT),\n  jobid :  jobid || 'jobid' ,\n  processingTime : process.env.PROCESSING_TIME  ,\n  error : process.env.IN_ERROR || false,\n  operation: 'Start'\n};\n// message key\nlet key = {jobid: jobid};\n\nconsole.log('Producer connection');\n\n\n// start consuming response\nvar consumer = new Kafka.KafkaConsumer({\n  //'debug': 'all',\n  'metadata.broker.list': process.env.BROKER_LIST,\n  'group.id': jobid,\n  'enable.auto.commit': true\n} , {\n    'auto.offset.reset' : 'earliest'\n});\n//logging debug messages, if debug is enabled\nconsumer.on('event.log', function(log) {\n  console.log(log);\n});\n//logging all errors\nconsumer.on('event.error',onConsumerError);\n// when consumer is ready , subscribe to topics\nconsumer.on('ready', function(arg) {\n  console.log('consumer ready.' + JSON.stringify(arg));\n  consumer.subscribe([topicToConsume]);\n  //start consuming messages\n  consumer.consume();\n  // Connect to the broker manually\n  producer.connect();\n  // Wait for the ready event before proceeding\n  producer.on('ready', function() {\n    try {\n      console.log('Producer is ready');\n      // send message to job trigger\n      producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n    } catch (err) {\n      console.error('A problem occurred when sending our message');\n      console.error(err);\n      process.exit(1)\n    }\n  });\n\n\n});\nconsumer.on('data', function(msg) {\n  // Output the actual message contents\n  console.log(JSON.stringify(msg));\n  let record = JSON.parse(msg.value.toString());\n  console.log('A message received');\n  if(record.jobid === jobid){\n    consumer.disconnect();\n    onNextMsgReceived(record);\n  }\n});\nconsumer.on('disconnected', function(arg) {\n  console.log('consumer disconnected. ' + JSON.stringify(arg));\n});\n//starting the consumer\nconsumer.connect();\n\nprocess.on('SIGTERM',()=>{\n  console.log('Sending a message to abort job');\n  consumer.disconnect();\n  trigger.operation = 'Abort';\n  // send message to job trigger\n  producer.produce(topicToProduce,null,new Buffer(JSON.stringify(trigger)),new Buffer(JSON.stringify(key)),Date.now(),);\n})\n\n\n/**\n* Function execute on next message from kafka for a consumer\n*/\nfunction onNextMsgReceived(value){\n  console.log(`Job response received ${value.jobid} , status : ${value.result} , percentage : ${value.percentage}`);\n  console.log(`${value.percentage}%`);\n  if(value.result === 'Success' && value.percentage === 100){\n    process.exit();\n  }else if (value.result === 'Failure'){\n    process.exit(1);\n  }\n}\n\n/**\n* Function to validate if environment variable are properly configured\n*\n*/\nfunction validate() {\n  if(!process.env.JOB_ID) {\n    console.error('JOBID not defined !');\n    process.exit(1);\n  }else if(!process.env.JOB_EVENT_TITLE) {\n    console.error('JOB_EVENT_TITLE not defined !');\n    process.exit(1);\n  } else if(!process.env.JOB_TIMEOUT){\n    console.error('JOB_TIMEOUT not defined !');\n    process.exit(1);\n  } else if(!process.env.TOPIC_TO_CONSUME) {\n    console.error('TOPIC_TO_CONSUME not defined !');\n    process.exit(1);\n  }else if(!process.env.TOPIC_TO_PRODUCE) {\n    console.error('TOPIC_TO_PRODUCE not defined !');\n    process.exit(1);\n  }else if(!process.env.BROKER_LIST) {\n    console.error('BROKER_LIST not defined !');\n    process.exit(1);\n  }\n}\n\n/**\n*   An error occurs during a topic creation , so you need to shutdown a consumer instance\n*/\nfunction onConsumerError(err){\n  console.log(`Something wrong consuming event ${topicToConsume} : ${err}`);\n  process.exit(1);\n}\n\n// Any errors we encounter, including connection errors\nproducer.on('event.error', function(err) {\n  console.error('Error from producer');\n  console.error(err);\n  process.exit(1);\n})\n","annotate":1,"json":1,"TOPIC_TO_CONSUME":"TriggerForecastOptimizationResponse","TOPIC_TO_PRODUCE":"TriggerForecastOptimization","BROKER_LIST":"localhost:9092"},"timeout":3600,"catch_up":0,"queue_max":1000,"timezone":"America/New_York","plugin":"shellplug","category":"general","algo":"random","multiplex":0,"stagger":0,"retries":0,"retry_delay":0,"detached":0,"queue":0,"chain":"","chain_error":"","notify_success":"","notify_fail":"","web_hook":"","cpu_limit":0,"cpu_sustain":0,"memory_limit":0,"memory_sustain":0,"notes":"","category_title":"General","group_title":"All Servers","plugin_title":"Shell Script","now":1526474000,"source":"Manual (admin)","id":"jjh937gna1b","time_start":1526474000.134,"hostname":"osboxes","event":"ejh8vu06v01","event_title":"ForecastOptimization","nice_target":"All Servers","command":"bin/shell-plugin.js","log_file":"/home/osboxes/git/cronicle-poc/custom-cronicle/Cronicle/logs/jobs/jjh937gna1b.log","pid":24347,"value":{"type":"Buffer","data":[123,34,116,105,109,101,111,117,116,34,58,32,51,54,48,48,44,32,34,106,111,98,105,100,34,58,32,34,70,111,114,101,99,97,115,116,79,112,116,105,109,105,122,97,116,105,111,110,106,106,104,57,51,55,103,110,97,49,98,34,44,32,34,114,101,115,117,108,116,34,58,32,34,83,117,99,99,101,115,115,34,44,32,34,112,101,114,99,101,110,116,97,103,101,34,58,32,49,48,48,125]},"size":101,"key":null,"topic":"TriggerForecastOptimizationResponse","offset":5,"partition":0,"timestamp":1526474001719,"progress":1,"complete":1,"code":0,"description":"","log_file_size":745,"time_end":1526474003.89,"elapsed":3.75600004196167}]
